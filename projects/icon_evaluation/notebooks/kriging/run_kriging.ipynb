{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
                "sys.path.insert( 0, lib_dir )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lib import *"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def write_subcells(number_of_cells, cell_id, spatial_resolution, east, north, elevation, pathout):\n",
                "    mkNestedDir(pathout)\n",
                "\n",
                "    header = \"{number_of_cells} {spatial_resolution} {spatial_resolution}\"\n",
                "    header = header.format(number_of_cells=number_of_cells, spatial_resolution=spatial_resolution)\n",
                "\n",
                "    cell_metadata = \"{id} 1\"\n",
                "    cell_metadata = cell_metadata.format(id=cell_id, spatial_resolution=spatial_resolution)\n",
                "\n",
                "    coordinates = \"{east} {north} {elevation} 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\"\n",
                "    coordinates = coordinates.format(east=east, north=north, elevation=elevation)\n",
                "\n",
                "    file = open(pathout+\"subcells.in\",\"w+\")\n",
                "    [file.writelines(el + \"\\n\") for el in [header, cell_metadata, coordinates]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def write_geometry(number_of_cells, spatial_resolution, pathout):\n",
                "    mkNestedDir(pathout)\n",
                "\n",
                "    header = \"{number_of_cells} {spatial_resolution}\"\n",
                "    header = header.format(number_of_cells=number_of_cells, spatial_resolution=spatial_resolution)\n",
                "\n",
                "    file = open(pathout+\"geometry.in\",\"w+\")\n",
                "    [file.writelines(el + \"\\n\") for el in [header]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def write_input(basin, grid_cells, pathout):\n",
                "    mkNestedDir(pathout)\n",
                "\n",
                "    line_1 = \"{basin}\"\n",
                "    line_2 = \"{grid_cells}\"\n",
                "    line_1 = line_1.format(basin=basin)\n",
                "    line_2 = line_2.format(grid_cells=grid_cells)\n",
                "\n",
                "    file = open(pathout+\"input.txt\",\"w+\")\n",
                "    [file.writelines(el + \"\\n\") for el in [line_1, line_2]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def write_params(variable, number_of_stations, kriging_type, kriging_model, kriging_correction, nugget, var, Ia, secs_timestep, starting_date, basin, pathout):\n",
                "    mkNestedDir(pathout)\n",
                "\n",
                "    line_1 = \"{Ia}  0   0   {var}   {nug}               ! Parameters for kriging (I_a, I_e, m, var, var_nug) --> variogr. precip.\"\n",
                "    line_2 = \"{Ia}  0   0   {var}   {nug}               ! Parameters for kriging (I_a, I_e, m, var, var_nug) --> variogr. temper.\"\n",
                "    line_3 = \"-999  -999    -999    -999    -999        ! Parameters for kriging (I_a, I_e, m, var, var_nug) --> TMIN\"\n",
                "    line_4 = \"-999  -999    -999    -999    -999        ! Parameters for kriging (I_a, I_e, m, var, var_nug) --> TMAX\"\n",
                "    line_5 = \"{number_of_stations}                      ! nk: number of neighbour meteorological stations used in the kriging\"\n",
                "    line_6 = \"{kriging_type}                            ! Type of Kriging OK, OKED\"\n",
                "    line_7 = \"{kriging_model}                           ! Model equation EXP, DBLE_EXP --> modello di semivariogramma\"\n",
                "    line_8 = \"{kriging_correction}\t\t\t\t        ! Correction of negative weights NO, RESET, ADD, DEUTSCH --> pesi negativi ogni tanto, per avere sum(pesi)=1\"\n",
                "    line_9 = \"{secs_timestep}                           ! Output time step [s]\"\n",
                "    line_10 = \"{var}                                    ! P = Rainfall,  T = Temperature\"\n",
                "    line_11 = \"{datetime}\t                            ! Starting date (measurements) yyyy/mm/dd hh:mm\"\n",
                "    line_12 = \"{basin}                                  ! Bacino\"\n",
                "    line_13 = \"0\t\t\t\t\t                    ! flag_varcond: 1--> evaluate conditional variance (0 --> otherwise)\"\n",
                "\n",
                "    if variable == \"temperature\":\n",
                "        line_1 = line_1.format(Ia=\"-999\", var=\"-999\", nug=\"-999\")\n",
                "        line_2 = line_2.format(Ia=Ia, var=var, nug=nugget)\n",
                "        line_10 = line_10.format(var=\"T\")\n",
                "\n",
                "    if variable == \"precipitation\":\n",
                "        line_2 = line_2.format(Ia=\"-999\", var=\"-999\", nug=\"-999\")\n",
                "        line_1 = line_1.format(Ia=Ia, var=var, nug=nugget)\n",
                "        line_10 = line_10.format(var=\"P\")\n",
                "\n",
                "    line_5 = line_5.format(number_of_stations=number_of_stations)\n",
                "    line_6 = line_6.format(kriging_type=kriging_type)\n",
                "    line_7 = line_7.format(kriging_model=kriging_model)\n",
                "    line_8 = line_8.format(kriging_correction=kriging_correction)\n",
                "    line_9 = line_9.format(secs_timestep=secs_timestep)\n",
                "    line_11 = line_11.format(datetime=starting_date)\n",
                "    line_12 = line_12.format(basin=basin)\n",
                "\n",
                "    file = open(pathout+\"kriging_params.in\",\"w+\")\n",
                "    [file.writelines(el + \"\\n\") for el in [line_1, line_2, line_3, line_4, line_5, line_6, line_7, line_8, line_9, line_10, line_11, line_12, line_13]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_kriging_input(weather_data_path, weather_input_dt_format, start_datetime, end_datetime):\n",
                "    dataset = pd.DataFrame(index=dates)\n",
                "    metadata = pd.DataFrame(index=range(1, 4))\n",
                "    big_frame = pd.DataFrame()\n",
                "\n",
                "    # percentage of no data allowed - range (0,1]\n",
                "    perc_filter = 1\n",
                "\n",
                "    # Get list of files available\n",
                "    files = os.listdir(weather_data_path)\n",
                "    # print(files)\n",
                "\n",
                "    # Loop over weather stations\n",
                "    for filename in files:\n",
                "\n",
                "        # Get station ID\n",
                "        IDstation = filename.split('.')[0]\n",
                "        print(\"Setup: \" + IDstation)\n",
                "\n",
                "        # Reading data\n",
                "        # \"/media/windows/projects/icon-evaluation/kriging/data/passirio/GS/precipitation/101.txt\"\n",
                "        # data = pd.read_csv(weather_data_path + filename, index_col=0, parse_dates=True, names=['datetime', 'values'], skiprows=4)\n",
                "        print(\"Opening: \" + weather_data_path + filename)\n",
                "        data = pd.read_csv(weather_data_path + filename,\n",
                "                           names=['datetime', 'values'])\n",
                "        # print(weather_data_path + filename)\n",
                "\n",
                "        # Extract time series in the required time window\n",
                "        # ts = pd.DataFrame( data.iloc[5:] )\n",
                "        # ts['datetime'] = [ dt.datetime.strptime(t, weather_input_dt_format) for t in ts['datetime'] ]\n",
                "        # ts.set_index('datetime', inplace=True)\n",
                "        ts = read_timeseries_pd(pd.read_csv(weather_data_path + filename, names=[\n",
                "                                'datetime', 'values'], skiprows=4), input_dt_format=weather_input_dt_format)\n",
                "        ts = ts[start_datetime:end_datetime]\n",
                "\n",
                "        n_no_data = 0\n",
                "        arr = []\n",
                "        for date in dates:\n",
                "            try:\n",
                "                if np.isnan(ts.loc[date][0]):\n",
                "                    # print('ERR: nan')\n",
                "                    raise\n",
                "                else:\n",
                "                    arr.append(ts.loc[date][0])\n",
                "                    # print('appending..')\n",
                "            except:\n",
                "                arr.append(np.nan)\n",
                "                n_no_data = n_no_data + 1\n",
                "\n",
                "        if n_no_data > perc_filter*len(arr):\n",
                "            continue\n",
                "        elif len(arr) == n_no_data:\n",
                "            print(\"MISSING: \" + str(IDstation))\n",
                "            continue\n",
                "        else:\n",
                "            # Extract metadata\n",
                "            metadata[IDstation] = data.iloc[1:4]['values']\n",
                "            # Populate the overall matrix of data\n",
                "            dataset[IDstation] = arr\n",
                "\n",
                "            big_frame = pd.concat([metadata, dataset])\n",
                "\n",
                "        print(\"End node: \" + IDstation)\n",
                "\n",
                "    # this imputation is just a workaround - TODO\n",
                "    # nan_indexes = big_frame[big_frame.isna().all(axis=1)]\n",
                "\n",
                "    # for j in [big_frame.index.get_loc(i) for i in nan_indexes.index]:\n",
                "    #     big_frame.iloc[j] = big_frame.iloc[j-1].values\n",
                "    \n",
                "    big_frame = big_frame.fillna(axis=0, method='ffill')\n",
                "    big_frame = big_frame.fillna(-999.0)\n",
                "\n",
                "    return big_frame\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#### SETUP ####\n",
                "wdir = \"/media/windows/projects/icon-evaluation/kriging/\"\n",
                "os.chdir(wdir)\n",
                "# wdir = \"/media/windows/projects/era5_bias/kriging/\"\n",
                "config_path = wdir + \"etc/config/\"\n",
                "input_path = wdir + \"input/\"\n",
                "\n",
                "### KRIGING MODEL SETUP\n",
                "## LINUX\n",
                "exe_path = wdir \n",
                "# exe_name = \"2020_06_kriging_PT.exe\"\n",
                "exe_name = \"kriging_v3\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inputs = glob.glob( input_path + \"*.json\" )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### for each input == configuration JSON file\n",
                "\n",
                "for input in inputs:\n",
                "    print(input)\n",
                "\n",
                "    setup_file = open(input)\n",
                "    setup_sim = json.load(setup_file)\n",
                "    variable = setup_sim[\"variable\"]\n",
                "\n",
                "    # coordinates = coordinates.format(\n",
                "    #     east=east, north=north, elevation=elevation)\n",
                "    # config_file = open(config_path + \"temperature.json\")\n",
                "    # file = open(pathout+\"subcells.in\", \"w+\")\n",
                "    # [file.writelines(el + \"\\n\") for el in [header, cell_metadata, coordinates]]\n",
                "\n",
                "    if variable == \"temperature\":\n",
                "        config_file = open(config_path + \"temperature.json\")\n",
                "    elif variable == \"precipitation\":\n",
                "        config_file = open(config_path + \"precipitation.json\")\n",
                "    else:\n",
                "        print( 'Not a valid variable: ' + variable )\n",
                "\n",
                "    params = json.load(config_file)\n",
                "\n",
                "    simulation_type = setup_sim[\"simulation_type\"]\n",
                "\n",
                "    basin = setup_sim[\"basin\"]\n",
                "    secs_timestep = setup_sim[\"secs_timestep\"]\n",
                "    number_of_stations = setup_sim[\"number_of_stations\"]\n",
                "    kriging_type = setup_sim[\"kriging_type\"]\n",
                "    kriging_model = params[\"kriging_model\"]\n",
                "    kriging_correction = setup_sim[\"kriging_correction\"]\n",
                "    grid_cells = setup_sim[\"grid_cells\"]\n",
                "\n",
                "    number_of_cells = len(setup_sim[\"cells\"])\n",
                "    print(\"Number of points: \" + str(number_of_cells))\n",
                "\n",
                "    timezone_str = setup_sim[\"timezone\"]\n",
                "    start_datetime_str = setup_sim[\"start_datetime\"]\n",
                "    start_datetime = dt.datetime.strptime(start_datetime_str, '%Y-%m-%dT%H:%M:%S')\n",
                "    end_datetime_str = setup_sim[\"end_datetime\"]\n",
                "    end_datetime = dt.datetime.strptime(end_datetime_str, '%Y-%m-%dT%H:%M:%S')\n",
                "    dates = [ start_datetime + dt.timedelta(hours=x) for x in range(0, (end_datetime-start_datetime).days*24) ]\n",
                "    steps = len(dates)\n",
                "\n",
                "    weather_data_path = wdir + setup_sim[\"weather_data_path\"]\n",
                "    weather_input_dt_format = setup_sim[\"input_dt_format\"]\n",
                "\n",
                "    path_kriging_inputs = wdir + basin + \"/input/\"\n",
                "    path_kriging_outputs = wdir + basin + \"/output/\"\n",
                "\n",
                "    kriging_input = generate_kriging_input(\n",
                "        weather_data_path, weather_input_dt_format, start_datetime, end_datetime)\n",
                "\n",
                "    if simulation_type == \"KR\":\n",
                "\n",
                "        station_number = len(kriging_input.columns)\n",
                "        buckets = [0] * (station_number - 3)\n",
                "        buckets.insert(0, secs_timestep)\n",
                "        buckets.insert(0, station_number)\n",
                "        buckets.insert(0, steps)\n",
                "\n",
                "        big_frame_meta = pd.DataFrame(\n",
                "            data=[buckets], columns=kriging_input.columns.values)\n",
                "        big_frame_id = pd.DataFrame(\n",
                "            data=[kriging_input.columns.values], columns=kriging_input.columns.values)\n",
                "        kriging_input = pd.concat(\n",
                "            [pd.concat([big_frame_meta, big_frame_id]), kriging_input])\n",
                "\n",
                "        if variable == \"temperature\":\n",
                "            kriging_input.to_csv(\n",
                "                path_kriging_inputs + \"TMEAN_\" + basin + \".in\", index=False, header=False)\n",
                "        elif variable == \"precipitation\":\n",
                "            kriging_input.to_csv(path_kriging_inputs + \"P_\" +\n",
                "                                 basin + \".in\", index=False, header=False)\n",
                "\n",
                "    sent_email = False\n",
                "\n",
                "    for i in range(number_of_cells):\n",
                "\n",
                "        station_name = setup_sim[\"cells\"][i][\"station_name\"]\n",
                "        station_id = setup_sim[\"cells\"][i][\"station_id\"]\n",
                "        east = setup_sim[\"cells\"][i][\"east\"]\n",
                "        north = setup_sim[\"cells\"][i][\"north\"]\n",
                "        elevation = setup_sim[\"cells\"][i][\"elevation\"]\n",
                "\n",
                "        print(station_id)\n",
                "\n",
                "        ###########################################################\n",
                "\n",
                "        start_sim_datetime = dt.datetime.now()\n",
                "\n",
                "        if simulation_type == \"CV\":\n",
                "            try:\n",
                "                kriging_input_tmp = kriging_input.drop(columns=str(station_id))\n",
                "                print(\"Excluded: \" + str(station_id))\n",
                "\n",
                "                station_number = len(kriging_input_tmp.columns)\n",
                "                buckets = [0] * (station_number - 3)\n",
                "                buckets.insert(0, secs_timestep)\n",
                "                buckets.insert(0, station_number)\n",
                "                buckets.insert(0, steps)\n",
                "\n",
                "                big_frame_meta = pd.DataFrame(\n",
                "                    data=[buckets], columns=kriging_input_tmp.columns.values)\n",
                "                big_frame_id = pd.DataFrame(\n",
                "                    data=[kriging_input_tmp.columns.values], columns=kriging_input_tmp.columns.values)\n",
                "                kriging_input_tmp = pd.concat(\n",
                "                    [pd.concat([big_frame_meta, big_frame_id]), kriging_input_tmp])\n",
                "\n",
                "                if variable == \"temperature\":\n",
                "                    kriging_input_tmp.to_csv(path_kriging_inputs + \"TMEAN_\" +\n",
                "                                            basin + \".in\", index=False, header=False)\n",
                "                elif variable == \"precipitation\":\n",
                "                    kriging_input_tmp.to_csv(path_kriging_inputs + \"P_\" +\n",
                "                                            basin + \".in\", index=False, header=False)\n",
                "            except:\n",
                "                print(\"Not in the JSON file: \" + str(station_id))\n",
                "                continue\n",
                "\n",
                "        write_params(variable, number_of_stations, kriging_type, kriging_model, kriging_correction, params[\"model_nugget\"],\n",
                "                     params[\"model_psill\"], params[\"model_range\"],\n",
                "                     secs_timestep, start_datetime.strftime(format='%Y/%m/%d %H:%M'), basin, path_kriging_inputs)\n",
                "\n",
                "        pathout_subcell = wdir + basin + \"/input/\" + grid_cells + \"/\"\n",
                "        write_input(basin, grid_cells, wdir)\n",
                "        write_subcells(1, station_id, 30, east, north,\n",
                "                       elevation, pathout_subcell)\n",
                "        write_geometry(1, 30, pathout_subcell)\n",
                "\n",
                "        print(\"RUN the model..\")\n",
                "\n",
                "        # RUN THE MODEL\n",
                "        path = exe_path\n",
                "        os.chdir(path)\n",
                "        # os.system(exe_name)\n",
                "        p = subprocess.Popen(exe_path + exe_name,\n",
                "                             stdin=subprocess.PIPE, shell=True)\n",
                "        p.communicate(input='\\n'.encode())\n",
                "\n",
                "        if variable == \"temperature\":\n",
                "            exe_output_name = path_kriging_outputs + \\\n",
                "                str(start_datetime.year) + \"_\" + \\\n",
                "                str(start_datetime.month) + \"/TMEAN_\" + basin + \".krig\"\n",
                "        elif variable == \"precipitation\":\n",
                "            exe_output_name = path_kriging_outputs + \\\n",
                "                str(start_datetime.year) + \"_\" + \\\n",
                "                str(start_datetime.month) + \"/P_\" + basin + \".krig\"\n",
                "\n",
                "        output_name = simulation_type + \"_\" + str(station_id) + \"_\" + station_name + \"_\" + kriging_type + \"_\" + \\\n",
                "            start_datetime.strftime(format='%Y%m%d') + \\\n",
                "            \"_\" + end_datetime.strftime(format='%Y%m%d')\n",
                "\n",
                "        # OUTPUT DIRECTORY\n",
                "        output_dir = wdir + setup_sim['output_path'] + variable + \"/\" + simulation_type + \\\n",
                "            \"/\" + kriging_type + \"/\" + kriging_correction + \"/\"\n",
                "        mkNestedDir(output_dir)\n",
                "\n",
                "        output_file = output_dir + output_name + \".csv\"\n",
                "        print(\"Moving output to: \" + output_file)\n",
                "        try:\n",
                "            os.rename(exe_output_name, output_file)\n",
                "        except FileExistsError:\n",
                "            os.remove(output_file)\n",
                "            os.rename(exe_output_name, output_file)\n",
                "\n",
                "        # POST-PROCESSING STATS\n",
                "        if bool(setup_sim['generate_stats']) == True and simulation_type == \"CV\":\n",
                "\n",
                "            model_output = pd.DataFrame( pd.read_csv(output_file, parse_dates=True)[str(station_id)].values, columns=[\"model\"])\n",
                "            model_output.index = dates\n",
                "            model_output = model_output[start_datetime:end_datetime]\n",
                "\n",
                "            model_output['model'] = pd.to_numeric(model_output['model'], errors='coerce')\n",
                "\n",
                "            # print(model_output)\n",
                "\n",
                "            if variable == \"temperature\":\n",
                "                model_output_hourly = model_output.resample(\"h\").mean()\n",
                "                model_output_daily = model_output.resample(\"d\").mean()\n",
                "                model_output_monthly = model_output.resample(\"MS\").mean()\n",
                "            if variable == \"precipitation\":\n",
                "                model_output_hourly = model_output.resample(\"h\").sum()\n",
                "                model_output_daily = model_output.resample(\"d\").sum()\n",
                "                model_output_monthly = model_output.resample(\"MS\").sum()\n",
                "\n",
                "                model_output_hourly = model_output_hourly.iloc[:, 0]\n",
                "                model_output_daily = model_output_daily.iloc[:, 0]\n",
                "                model_output_monthly = model_output_monthly.iloc[:, 0]\n",
                "\n",
                "            data_length = len(model_output)\n",
                "\n",
                "            # read observed data\n",
                "            obs_data_name = weather_data_path + str(station_id) + \".txt\"\n",
                "            print(\"Opening: \" + obs_data_name)\n",
                "\n",
                "            # obs_data = read_timeseries_pd( pd.read_csv(obs_data_name, skiprows=4, names=['datetime', 'obs']), '%Y-%m-%dT%H:%M:%S.%f%z' )\n",
                "            obs_data = read_timeseries_pd( pd.read_csv(obs_data_name, skiprows=4, names=['datetime', 'obs']), weather_input_dt_format )\n",
                "\n",
                "            # print(obs_data)\n",
                "\n",
                "            obs_data = obs_data[start_datetime:end_datetime]\n",
                "            obs_data[obs_data == -999] = None\n",
                "            if variable == \"temperature\":\n",
                "                obs_data_hourly = obs_data.resample(\"h\").mean()\n",
                "                obs_data_daily = obs_data.resample(\"d\").mean()\n",
                "                obs_data_monthly = obs_data.resample(\"MS\").mean()\n",
                "            if variable == \"precipitation\":\n",
                "                obs_data_hourly = obs_data.resample(\"h\").sum()\n",
                "                obs_data_daily = obs_data.resample(\"d\").sum()\n",
                "                obs_data_monthly = obs_data.resample(\"MS\").sum()\n",
                "\n",
                "            print(\"Evaluating stats:\")\n",
                "\n",
                "            output_path_stats = output_dir + \"stats/\"\n",
                "            mkNestedDir(output_path_stats)\n",
                "\n",
                "            # print(obs_data_hourly)\n",
                "            \n",
                "            # evaluate stats\n",
                "            df_all_hourly = pd.concat( [obs_data_hourly, model_output_hourly], axis=1 )\n",
                "            df_all_hourly.dropna(inplace=True)\n",
                "\n",
                "            if not( df_all_hourly.empty ):\n",
                "\n",
                "                rmse_hourly = mean_squared_error( df_all_hourly[\"obs\"], df_all_hourly[\"model\"], squared=False)\n",
                "                mae_hourly = mean_absolute_error( df_all_hourly[\"obs\"], df_all_hourly[\"model\"] )\n",
                "                r2_hourly = r2_score( df_all_hourly[\"obs\"], df_all_hourly[\"model\"] )\n",
                "                \n",
                "                df_all_daily = pd.concat( [obs_data_daily, model_output_daily], axis=1 )\n",
                "                df_all_daily.dropna(inplace=True)\n",
                "\n",
                "                rmse_daily = mean_squared_error( df_all_daily[\"obs\"], df_all_daily[\"model\"], squared=False)\n",
                "                mae_daily = mean_absolute_error( df_all_daily[\"obs\"], df_all_daily[\"model\"] )\n",
                "                r2_daily = r2_score( df_all_daily[\"obs\"], df_all_daily[\"model\"] )\n",
                "\n",
                "                df_all_monthly = pd.concat( [obs_data_monthly, model_output_monthly], axis=1 )\n",
                "                df_all_monthly.dropna(inplace=True)\n",
                "\n",
                "                rmse_monthly = mean_squared_error( df_all_monthly[\"obs\"], df_all_monthly[\"model\"], squared=False)\n",
                "                mae_monthly = mean_absolute_error( df_all_monthly[\"obs\"], df_all_monthly[\"model\"] )\n",
                "                r2_monthly = r2_score( df_all_monthly[\"obs\"], df_all_monthly[\"model\"] )\n",
                "\n",
                "                # rmse_monthly = np.sqrt(\n",
                "                #     (1/data_length) * np.nansum((obs_data_monthly.T.values - model_output_monthly.values)**2))\n",
                "                # cc_monthly = np.ma.corrcoef(np.ma.masked_invalid(\n",
                "                #     model_output_monthly.values), np.ma.masked_invalid(obs_data_monthly.T.values))\n",
                "                # mae_monthly = (np.nansum(\n",
                "                #     np.abs(obs_data_monthly.T.values - model_output_monthly.values)))/data_length\n",
                "\n",
                "                stats_df = pd.DataFrame(columns=['RMSE', 'R2', 'MAE'])\n",
                "                stats_df['timestep'] = [\"hourly\", \"daily\", \"monthly\"]\n",
                "                stats_df['RMSE'] = [rmse_hourly, rmse_daily, rmse_monthly]\n",
                "                stats_df['R2'] = [r2_hourly, r2_daily, r2_monthly]\n",
                "                stats_df['MAE'] = [mae_hourly, mae_daily, mae_monthly]\n",
                "\n",
                "                stats_df.set_index('timestep', inplace=True)\n",
                "\n",
                "                output_file_stats = output_path_stats + output_name + \".txt\"\n",
                "                print(\"Exporting to: \" + output_file_stats)\n",
                "                stats_df.to_csv(output_file_stats)\n",
                "\n",
                "        end_sim_datetime = dt.datetime.now()\n",
                "\n",
                "        if sent_email == False:\n",
                "\n",
                "            simulation_step_time = end_sim_datetime.second - start_sim_datetime.second\n",
                "            send_email(subject=simulation_type + \" | computation started\", body=\"Started \" + str(input) +\n",
                "                       \"\\nNumber of points: \" + str(number_of_cells) +\n",
                "                       \"\\nEstimated finish: \" + str(dt.datetime.now() + dt.timedelta(seconds=simulation_step_time*number_of_cells)) +\n",
                "                       \"\\n\" + str(json.dumps(setup_sim, indent=4)))\n",
                "            sent_email = True\n",
                "    \n",
                "    if bool(setup_sim['generate_stats']) == True and simulation_type == \"CV\":\n",
                "\n",
                "        outputs = glob.glob(output_path_stats + \"*.txt\")\n",
                "\n",
                "        # create stats\n",
                "        sum_hourly_rmse = 0.0\n",
                "        sum_daily_rmse = 0.0\n",
                "        sum_monthly_rmse = 0.0\n",
                "\n",
                "        sum_hourly_mae = 0.0\n",
                "        sum_daily_mae = 0.0\n",
                "        sum_monthly_mae = 0.0\n",
                "\n",
                "        sum_hourly_r2 = 0.0\n",
                "        sum_daily_r2 = 0.0\n",
                "        sum_monthly_r2 = 0.0\n",
                "\n",
                "        for out in outputs:\n",
                "\n",
                "            # print(os.path.basename(out).split(\"_\"))\n",
                "\n",
                "            out_stats = pd.read_csv(out, index_col=0)\n",
                "            sum_hourly_rmse = sum_hourly_rmse + \\\n",
                "                float(out_stats.loc[\"hourly\"][\"RMSE\"])\n",
                "            sum_daily_rmse = sum_daily_rmse + float(out_stats.loc[\"daily\"][\"RMSE\"])\n",
                "            sum_monthly_rmse = sum_monthly_rmse + \\\n",
                "                float(out_stats.loc[\"monthly\"][\"RMSE\"])\n",
                "\n",
                "            sum_hourly_mae = sum_hourly_mae + float(out_stats.loc[\"hourly\"][\"MAE\"])\n",
                "            sum_daily_mae = sum_daily_mae + float(out_stats.loc[\"daily\"][\"MAE\"])\n",
                "            sum_monthly_mae = sum_monthly_mae + \\\n",
                "                float(out_stats.loc[\"monthly\"][\"MAE\"])\n",
                "\n",
                "            sum_hourly_r2 = sum_hourly_r2 + float(out_stats.loc[\"hourly\"][\"R2\"])\n",
                "            sum_daily_r2 = sum_daily_r2 + float(out_stats.loc[\"daily\"][\"R2\"])\n",
                "            sum_monthly_r2 = sum_monthly_r2 + float(out_stats.loc[\"monthly\"][\"R2\"])\n",
                "\n",
                "        rmse_hourly_mean = sum_hourly_rmse / len(outputs)\n",
                "        rmse_daily_mean = sum_daily_rmse / len(outputs)\n",
                "        rmse_monthly_mean = sum_monthly_rmse / len(outputs)\n",
                "\n",
                "        mae_hourly_mean = sum_hourly_mae / len(outputs)\n",
                "        mae_daily_mean = sum_daily_mae / len(outputs)\n",
                "        mae_monthly_mean = sum_monthly_mae / len(outputs)\n",
                "\n",
                "        r2_hourly_mean = sum_hourly_r2 / len(outputs)\n",
                "        r2_daily_mean = sum_daily_r2 / len(outputs)\n",
                "        r2_monthly_mean = sum_monthly_r2 / len(outputs)\n",
                "\n",
                "        data = [[\"hourly\", rmse_hourly_mean, mae_hourly_mean, r2_hourly_mean],\n",
                "                [\"daily\", rmse_daily_mean, mae_daily_mean, r2_daily_mean],\n",
                "                [\"monthly\", rmse_monthly_mean, mae_monthly_mean, r2_monthly_mean]]\n",
                "\n",
                "        output_stats = pd.DataFrame(data, columns=[\"timestep\", \"RMSE\", \"MAE\", \"R2\"])\n",
                "        output_stats.set_index(\"timestep\", inplace=True)\n",
                "\n",
                "        output_stats.to_csv( output_path_stats + \"00_statistics_mean.txt\" )\n",
                "\n",
                "    send_email(subject=simulation_type + \" | computation done\", body=\"Ended: \" + str(input))"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        },
        "kernelspec": {
            "display_name": "Python 3.8.10 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
