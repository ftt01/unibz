{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
    "sys.path.insert( 0, lib_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from dateutil import tz\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNash(data_obs, data_sim, round_el=5):\n",
    "    from numpy import nanmean, nansum\n",
    "    num_nse = nansum((data_obs - data_sim)**2)\n",
    "    den_nse = nansum((data_obs - nanmean(data_obs))**2)\n",
    "    nse = 1 - num_nse/den_nse\n",
    "    return round(nse, round_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNNSE(nse, round_el=5):\n",
    "    return round(1/(2-nse), round_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_current(forecast_df, observed_df, filename, output_path):\n",
    "    \n",
    "    plots = []\n",
    "\n",
    "    ### fct plot ###\n",
    "    plt_conf = {}\n",
    "    plt_conf[\"label\"] = 'forecast'\n",
    "    plt_conf[\"color\"] = '#5e3c99'\n",
    "    plots.append( (forecast_df, plt_conf) )\n",
    "\n",
    "    ### obs plot ###\n",
    "    plt_conf = {}\n",
    "    plt_conf[\"label\"] = 'Observed'\n",
    "    plt_conf[\"color\"] = '#fdb863'\n",
    "    plots.append( (observed_df, plt_conf) )\n",
    "\n",
    "    createPlot(plots,  \"Time $[hour]$\", \"Streamflow $[m^3/hour]$\",\n",
    "           output_path + \"HD/\" + filename + \".\" + output_format, output_format=output_format, my_dpi=600)\n",
    "\n",
    "    createPlot(plots,  \"Time $[hour]$\", \"Streamflow $[m^3/hour]$\",\n",
    "           output_path + \"LD/\"+ filename + \".\" + output_format, output_format=output_format, my_dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = \"/media/windows/projects/icon-evaluation/hydro_modeling/\"\n",
    "os.chdir(wdir)\n",
    "\n",
    "basin = \"passirio\"\n",
    "\n",
    "start_date_str = '2021-07-01 00:00:00'\n",
    "end_date_str = '2021-10-01 00:00:00'\n",
    "timezone_str = 'Europe/Rome'\n",
    "\n",
    "start_date = dt.datetime.strptime(\n",
    "    start_date_str, '%Y-%m-%d %H:%M:%S')\n",
    "end_date = dt.datetime.strptime(\n",
    "    end_date_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "dates = [start_date + dt.timedelta(hours=x)\n",
    "         for x in range(1, (end_date-start_date).days*24 + 1)]\n",
    "\n",
    "# station_meta = [{\"point\": \"15\",\n",
    "#                  \"names\": \"plan\",\n",
    "#                  \"gauge\": \"155\"}]\n",
    "\n",
    "station_meta = [{\"point\": \"58\",\n",
    "                 \"names\": \"merano\",\n",
    "                 \"gauge\": \"118\"}]\n",
    "                 \n",
    "gauge_station = '58' ### merano\n",
    "gauge_measure = '118'\n",
    "\n",
    "# gauge_station = '15' ### plan\n",
    "# gauge_measure = '155'\n",
    "\n",
    "flow_min = 0\n",
    "flow_max = 200\n",
    "\n",
    "nash_months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path =  wdir + basin + \"/\"\n",
    "output_path =  wdir + basin + \"/results/\"\n",
    "mkNestedDir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_path = model_path + \"meteo/streamflow/\"\n",
    "stations_path = glob.glob(obs_path + \"*.txt\")\n",
    "\n",
    "obs_dataframe = pd.DataFrame(index=dates)\n",
    "obs_dataframe.index.name = 'datetime'\n",
    "\n",
    "for obs_flow_filepath in stations_path:\n",
    "\n",
    "    station_name = os.path.basename(obs_flow_filepath)[:-4]\n",
    "\n",
    "    obs_flow = pd.read_csv( obs_flow_filepath, skiprows=5, index_col=0, names=[station_name])\n",
    "    obs_flow.index.name = 'datetime'\n",
    "    obs_flow.index = [dt.datetime.strptime(\n",
    "        i, '%Y-%m-%d %H:%M:%S') for i in obs_flow.index]\n",
    "\n",
    "    obs_flow = obs_flow[ obs_flow[station_name] >= flow_min ]\n",
    "    obs_flow = obs_flow[ obs_flow[station_name] <= flow_max ]\n",
    "\n",
    "    obs_dataframe[station_name] = obs_flow\n",
    "\n",
    "obs_dataframe_partial = obs_dataframe[obs_dataframe.index.month.isin(nash_months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataframe = pd.DataFrame(index=dates)\n",
    "model_dataframe.index.name = 'datetime'\n",
    "\n",
    "model_output_path = model_path + \"OUTPUT/FORWARD/\"\n",
    "list_output_runs_path = glob.glob(model_output_path + \"*/\")\n",
    "\n",
    "nash_table = pd.DataFrame(index=[], columns=['NASH', 'NNSE', 'RMSE', 'MAE'])\n",
    "\n",
    "for out_dir in list_output_runs_path:\n",
    "\n",
    "    try:\n",
    "        run_id = os.path.dirname(out_dir).split(\"_\")[-1]\n",
    "        nash_table = nash_table.reindex(\n",
    "            nash_table.index.append(pd.Index([run_id])))\n",
    "\n",
    "        ## read streamflow from the model - skip IC bug\n",
    "        model_streamflow = pd.read_csv(\n",
    "            out_dir + \"/out_flow.txt\", index_col=0)\n",
    "        model_streamflow.index.name = 'datetime'\n",
    "        model_streamflow.index = [dt.datetime.strptime(\n",
    "            i, '%Y-%m-%d %H:%M') for i in model_streamflow.index]\n",
    "\n",
    "        for st in station_meta:\n",
    "\n",
    "            # print(st)\n",
    "\n",
    "            # model_dataframe[st[\"point\"]] = model_streamflow[model_streamflow[st[\"point\"]].between(flow_min, flow_max)][st[\"point\"]]\n",
    "            model_dataframe = model_streamflow[[st[\"point\"]]]\n",
    "\n",
    "            metrics_data = pd.DataFrame()\n",
    "            metrics_data['obs'] = obs_dataframe_partial[st[\"gauge\"]]\n",
    "            metrics_data['model'] = model_dataframe[model_dataframe.index.month.isin(nash_months)][st[\"point\"]]\n",
    "            ### to avoid str in the model results '********' bug of ICHYMOD\n",
    "            metrics_data['model'] = pd.to_numeric(metrics_data['model'], downcast=\"float\", errors='coerce')\n",
    "\n",
    "            metrics_data.dropna(how='any', inplace=True)\n",
    "\n",
    "            # plot_current(metrics_data[['model']], metrics_data[['obs']], str(run_id), output_path)\n",
    "\n",
    "            try:\n",
    "                if len(metrics_data) == 0:\n",
    "                    raise\n",
    "                nash_table.loc[run_id]['NASH'] = evaluateNash(\n",
    "                    metrics_data['obs'], metrics_data['model'])\n",
    "            except:\n",
    "                print(\"NASH not evaluated!\")\n",
    "                nash_table.loc[run_id]['NASH'] = np.nan\n",
    "\n",
    "            try:\n",
    "                nash_table.loc[run_id]['RMSE'] = mean_squared_error(\n",
    "                    metrics_data['obs'], metrics_data['model'], squared=True)\n",
    "            except:\n",
    "                print(\"RMSE not evaluated!\")\n",
    "                nash_table.loc[run_id]['RMSE'] = np.nan\n",
    "\n",
    "            try:\n",
    "                nash_table.loc[run_id]['MAE'] = mean_absolute_error(\n",
    "                    metrics_data['obs'], metrics_data['model'])\n",
    "            except:\n",
    "                print(\"MAE not evaluated!\")\n",
    "                nash_table.loc[run_id]['MAE'] = np.nan\n",
    "            \n",
    "        #     break\n",
    "        # break\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "nash_table['NNSE'] = [evaluateNNSE(n) for n in nash_table['NASH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_max_nash = pd.to_numeric(nash_table['NASH']).idxmax()\n",
    "max_nash = nash_table['NASH'][i_max_nash]\n",
    "print( \"NSE [-inf:1.0] max: \" + str(max_nash) + \" at simulation #\" + str(i_max_nash) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20210213 > NSE [-inf:1.0] max: 0.65385 at simulation #216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_table[nash_table['NASH'] > 0.1].sort_values('MAE', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_flow_filepath = wdir + basin + \"/OUTPUT/FORWARD/output_{id}/\".format(id=i_max_nash)\n",
    "streamflow_df = pd.DataFrame()\n",
    "\n",
    "### measured ###\n",
    "obs_flow = pd.read_csv(wdir + basin + \"/meteo/streamflow/\" + gauge_measure +\n",
    "                           \".txt\", skiprows=5, header=None, parse_dates=True, index_col=0)\n",
    "obs_flow.index.name = 'datetime'\n",
    "obs_flow = obs_flow[start_date:end_date]\n",
    "\n",
    "streamflow_df['measured'] = obs_flow[obs_flow[1] > 0][1]\n",
    "\n",
    "### forward ###\n",
    "model_streamflow = pd.read_csv(obs_flow_filepath + 'out_flow.txt', index_col=0)\n",
    "\n",
    "model_streamflow = model_streamflow[[st[\"point\"]]]\n",
    "model_streamflow.index.name = 'datetime'\n",
    "model_streamflow.index = [dt.datetime.strptime(\n",
    "            i, '%Y-%m-%d %H:%M') for i in model_streamflow.index]\n",
    "            \n",
    "model_streamflow[st[\"point\"]] = pd.to_numeric(model_streamflow[st[\"point\"]], downcast=\"float\", errors='coerce')\n",
    "\n",
    "model_streamflow = model_streamflow[start_date:end_date]\n",
    "\n",
    "streamflow_df['forward'] = model_streamflow\n",
    "\n",
    "streamflow_df.plot(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_kr_path = wdir + basin + \"/meteo/GS/observations/precipitation.txt\"\n",
    "\n",
    "precipitation_kr = pd.read_csv(precipitation_kr_path, sep=\"\\s+\")\n",
    "precipitation_kr.reset_index(inplace=True)\n",
    "\n",
    "dates = [ str(date) for date in precipitation_kr['index'] ] \n",
    "hours = [ str(hour) for hour in precipitation_kr['date'] ] \n",
    "\n",
    "datetimes = []\n",
    "for i in range(len(dates)):\n",
    "    d = dt.datetime.strptime(dates[i], '%Y-%m-%d')\n",
    "    datetimes.append(d + dt.timedelta(hours=int(hours[i])))\n",
    "\n",
    "precipitation_kr.drop(columns=['index', 'date'], inplace=True)\n",
    "\n",
    "precipitation_kr.index = datetimes\n",
    "\n",
    "precipitation_kr = precipitation_kr.mean(axis=1)[start_date:end_date]\n",
    "\n",
    "precipitation_kr.plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
