{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "lib_dir = \"/home/daniele/documents/github/ftt01/phd/share/lib\"\n",
    "sys.path.insert( 0, lib_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "basin = 'trentino_alto_adige'\n",
    "\n",
    "input_path = '/media/lacie2022/data/meteo/dwd/icon-d2-eps/tmp/'\n",
    "output_path = '/media/windows/projects/hydrological_forecasting/data/forecast/postprocessed/'\n",
    "\n",
    "# init_ref = '03'\n",
    "# lead_hours = 45\n",
    "# lag_hours = 24*3\n",
    "\n",
    "# ensemble_number = 20\n",
    "\n",
    "# start_date_str = '20210615T00:00:00'\n",
    "# end_date_str = '20211016T00:00:00'\n",
    "# timezone_str = 'Europe/Rome'\n",
    "# timezone = ZoneInfo(timezone_str)\n",
    "\n",
    "# station_id = 118 ## ID from extracted data GRIB2\n",
    "\n",
    "# ## Passirio basin\n",
    "# out_basin = 'passirio'\n",
    "# lat = ( 46.68, 46.945 )\n",
    "# lon = ( 11.015, 11.38 )\n",
    "# points = [255, 256,\n",
    "#           234, 235, 236, 237, 238,\n",
    "#           214, 215, 216, 217, 218, 219,\n",
    "#           195, 196, 197, 198, 199, 200,\n",
    "#           175, 176, 177, 178, 179, 180, 181,\n",
    "#           156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
    "#           137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
    "#           116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
    "#           97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
    "#           77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91,\n",
    "#           59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
    "#           41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
    "#           27, 28, 29, 30, 31, 32]\n",
    "\n",
    "# ## Passirio station\n",
    "# lat = ( , )\n",
    "# lon = ( , )\n",
    "\n",
    "# # Plan basin\n",
    "# out_basin = 'plan'\n",
    "# lat = (46.7145853, 46.8251415)\n",
    "# lon = (11.0198472, 11.117037)\n",
    "# points = [137,\n",
    "#           116, 117, 118, 119, 120,\n",
    "#           97, 98, 99, 100, 101, 102,\n",
    "#           77, 78, 79, 80, 81, 82,\n",
    "#           59, 60, 61,\n",
    "#           41]\n",
    "\n",
    "# # Plan station\n",
    "# lat = ( , )\n",
    "# lon = ( , )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = dt.datetime.strptime(start_date_str, \"%Y%m%dT%H:%M:%S\").replace(\n",
    "#     tzinfo=ZoneInfo(timezone_str)\n",
    "# )\n",
    "# end_date = dt.datetime.strptime(end_date_str, \"%Y%m%dT%H:%M:%S\").replace(\n",
    "#     tzinfo=ZoneInfo(timezone_str)\n",
    "# )\n",
    "\n",
    "# dates = [\n",
    "#     start_date + dt.timedelta(days=x) for x in range(0, (end_date - start_date).days)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = glob.glob(input_path + '*/')\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles = range(1, ensemble_number + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### extract data for each point in the out_basin\n",
    "\n",
    "# for dir in dirs:\n",
    "\n",
    "#     for variable in variables:\n",
    "\n",
    "#         print('Variable: ' + variable)\n",
    "\n",
    "#         if variable == 'temperature':\n",
    "#             var = 't_2m'\n",
    "#         elif variable == 'precipitation':\n",
    "#             var = 'tot_prec'\n",
    "\n",
    "#         datetime_str = os.path.dirname(dir)[-8:]\n",
    "#         print(datetime_str)\n",
    "\n",
    "#         current_date = dt.datetime.strptime(datetime_str, '%Y%m%d')\n",
    "#         current_date = current_date.astimezone(timezone)\n",
    "\n",
    "#         if current_date in dates:\n",
    "\n",
    "#             print('Date: ' + str(current_date) )\n",
    "\n",
    "#             for point in points:\n",
    "\n",
    "#                 # print(point)\n",
    "\n",
    "#                 current_dates = []\n",
    "#                 values = []\n",
    "#                 ensemble_index = [ str(e).zfill(3) for e in range(1,ensemble_number+1) ]\n",
    "#                 fct_df = pd.DataFrame( index=ensemble_index )\n",
    "\n",
    "#                 for n in range(1, lead_hours+1):\n",
    "\n",
    "#                     current_dates.append(\n",
    "#                             current_date + dt.timedelta(hours=(int(init_ref) + n)))\n",
    "\n",
    "#                     n = str(n).zfill(3)\n",
    "\n",
    "#                     current_value = []\n",
    "#                     ensemble_value = []\n",
    "#                     for ensemble in ensembles:\n",
    "\n",
    "#                         ensemble_str = str(ensemble).zfill(3)\n",
    "                        \n",
    "#                         current_file = pd.read_csv(\n",
    "#                             dir + n + '/' + in_basin + '/' + var + '/' + ensemble_str + '/' + 'output.csv', index_col=0)\n",
    "\n",
    "#                         current_value = current_file[current_file['ID'] == int(point)]['values'].values[0]\n",
    "\n",
    "#                         if variable == 'temperature':\n",
    "#                             ensemble_value.append( round(\n",
    "#                                 current_value - 273.15, 2) )\n",
    "#                         elif variable == 'precipitation':\n",
    "#                             ensemble_value.append( round(\n",
    "#                                 abs(current_value), 2) )\n",
    "#                         else:\n",
    "#                             print(\"ERROR: not a valid variable!\")\n",
    "                    \n",
    "#                     fct_df[ n ] = ensemble_value\n",
    "\n",
    "#                 if variable == 'precipitation':\n",
    "\n",
    "#                     ## to solve cumulative problem\n",
    "#                     # for n in range(1, lead_hours+1):\n",
    "                        \n",
    "#                     #     lead_hour_str = str(n).zfill(3)\n",
    "#                     #     if n-1 > 0:\n",
    "#                     #         lead_hour_str_last = str(n-1).zfill(3)\n",
    "\n",
    "#                     #         fct_df.sort_values(by=lead_hour_str_last, inplace=True)\n",
    "#                     #         to_sort = fct_df[lead_hour_str]\n",
    "#                     #         fct_df.drop(columns=lead_hour_str, inplace=True)\n",
    "#                     #         fct_df[lead_hour_str] = to_sort.sort_values().values\n",
    "\n",
    "#                     ## to reorder the last based on the next to last\n",
    "#                     bug_hour = 16\n",
    "#                     lead_time_bug = str(bug_hour).zfill(3)\n",
    "#                     before_bug = str(bug_hour-1).zfill(3)\n",
    "#                     after_bug = str(bug_hour+1).zfill(3)\n",
    "#                     fct_df.drop(columns=lead_time_bug, inplace=True)\n",
    "#                     fct_df[lead_time_bug] = (fct_df[after_bug].values + fct_df[before_bug].values)/2\n",
    "\n",
    "#                     # bug_hour = 44\n",
    "#                     # next_to_bug = str(bug_hour-1).zfill(3)\n",
    "#                     # bug_lead_time = str(bug_hour).zfill(3)\n",
    "#                     # fct_df.sort_values(by=next_to_bug, inplace=True)\n",
    "#                     # to_sort = fct_df[bug_lead_time]\n",
    "#                     # fct_df.drop(columns=bug_lead_time, inplace=True)\n",
    "#                     # fct_df[bug_lead_time] = to_sort.sort_values().values\n",
    "\n",
    "#                     ## to reorder the last based on the next to last\n",
    "#                     next_to_last = str(lead_hours-1).zfill(3)\n",
    "#                     last_lead_time = str(lead_hours).zfill(3)\n",
    "#                     fct_df.sort_values(by=next_to_last, inplace=True)\n",
    "#                     to_sort = fct_df[last_lead_time]\n",
    "#                     fct_df.drop(columns=last_lead_time, inplace=True)\n",
    "#                     fct_df[last_lead_time] = to_sort.sort_values().values\n",
    "\n",
    "#                     fct_final = pd.DataFrame( index=ensemble_index )\n",
    "#                     for en in range(1,lead_hours+1):\n",
    "#                         fct_final[str(en).zfill(3)] = fct_df[str(en).zfill(3)]\n",
    "\n",
    "#                     fct_df = fct_final.T\n",
    "            \n",
    "#                     for ens in ensembles:\n",
    "\n",
    "#                         ens = str(ens).zfill(3)\n",
    "\n",
    "#                         ens_value = fct_df[ens].values\n",
    "\n",
    "#                         # print(ens_value)\n",
    "\n",
    "#                         val = []\n",
    "#                         val.append( ens_value[0] )\n",
    "#                         for i in range(1, len(ens_value)):\n",
    "#                             val.append( ens_value[i] - ens_value[i-1] )\n",
    "\n",
    "#                         # print(tmp)\n",
    "\n",
    "#                         fct_df[ens] = [round(v, 2) for v in val]\n",
    "#                 else:\n",
    "#                     fct_df = fct_df.T\n",
    "             \n",
    "#                 fct_df.index = current_dates\n",
    "#                 fct_df.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in fct_df.index ]\n",
    "#                 fct_df.index.name = 'datetime'\n",
    "            \n",
    "#                 output_file = output_path + out_basin + '/' + variable + '/ensemble/' + str(point).zfill(3) + '/' + datetime_str + '.csv'\n",
    "#                 mkNestedDir(os.path.dirname(output_file))\n",
    "#                 fct_df.to_csv(output_file, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir in dirs:\n",
    "\n",
    "#     datetime_str = os.path.dirname(dir)[-8:]\n",
    "#     print(datetime_str)\n",
    "\n",
    "#     for variable in variables:\n",
    "\n",
    "#         print('Variable: ' + variable)\n",
    "\n",
    "#         point_matrix = pd.DataFrame()\n",
    "\n",
    "#         for point in points:\n",
    "\n",
    "#             point_id = str(point).zfill(3)\n",
    "\n",
    "#             file_to_read = output_path + out_basin + '/' + variable + '/ensemble/' + point_id + '/' + datetime_str + '.csv'\n",
    "\n",
    "#             current_file = pd.read_csv( file_to_read, parse_dates=[0], index_col=0, sep=';' )\n",
    "                \n",
    "#             tmp = []\n",
    "#             for hour in range( lead_hours ):\n",
    "#                 tmp.append( current_file.iloc[hour].to_list() )\n",
    "            \n",
    "#             point_matrix[point_id] = tmp\n",
    "\n",
    "#         point_matrix.index = current_file.index\n",
    "\n",
    "#         mean_matrix = pd.DataFrame(index=[l for l in range(1,ensemble_number+1)])\n",
    "\n",
    "#         for i in range(lead_hours):\n",
    "#             ensemble_spatial_mean = []\n",
    "#             for k in range(ensemble_number):\n",
    "#                 ensemble_array = []\n",
    "#                 for j in points:\n",
    "#                     point_id = str(j).zfill(3)\n",
    "#                     ensemble_array.append( point_matrix.iloc[i][point_id][k] )\n",
    "#                 ensemble_spatial_mean.append( round(np.mean(ensemble_array), 2) )\n",
    "#             mean_matrix[point_matrix.index[i]] = ensemble_spatial_mean\n",
    "\n",
    "#         mean_matrix = mean_matrix.T\n",
    "#         mean_matrix.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in mean_matrix.index ]\n",
    "#         mean_matrix.index.name = 'datetime'\n",
    "#         mean_matrix.columns = [str(m).zfill(3) for m in mean_matrix.columns]\n",
    "\n",
    "#         output_file = output_path + out_basin + '/' + variable + '/ensemble/spatial_mean/' + datetime_str + '.csv'\n",
    "#         mkNestedDir(os.path.dirname(output_file))\n",
    "#         mean_matrix.to_csv(output_file, sep=';')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
