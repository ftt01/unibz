{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = \"/home/daniele/documents/github/ftt01/phd/projects/hydrological_forecasting/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTs\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# to link the lib in py scripts as well\n",
    "os.chdir(wdir)\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(os.getcwd()), 'lib'))\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from dateutil import tz\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "in_basin = 'passirio'\n",
    "variables = ['precipitation', 'temperature']\n",
    "\n",
    "data_path = '/media/windows/projects/hydro_forecasting/machine_learning/data/forecast/icon-d2-eps_45h/done/'\n",
    "# output_path = \"/media/windows/projects/hydrological_forecasting/machine_learning/data/forecast/icon-d2-eps_45h/postprocess/\"\n",
    "output_path = '/media/windows/projects/hydro_forecasting/machine_learning/data/forecast/icon-d2-eps_45h/postprocessed/'\n",
    "\n",
    "init_ref = '03'\n",
    "lead_hours = 45\n",
    "lag_hours = 24*3\n",
    "\n",
    "ensemble_number = 20\n",
    "reorder_ensembles = False\n",
    "\n",
    "output_types = ['mean', 'median', 'first_quantile', 'third_quantile']\n",
    "\n",
    "start_date_str = '20210615T00:00:00'\n",
    "end_date_str = '20211016T00:00:00'\n",
    "timezone_str = 'Europe/Rome'\n",
    "timezone = ZoneInfo(timezone_str)\n",
    "\n",
    "# station_id = 118 ## ID from extracted data GRIB2\n",
    "\n",
    "# ## Passirio basin\n",
    "# out_basin = 'passirio'\n",
    "# lat = ( 46.68, 46.945 )\n",
    "# lon = ( 11.015, 11.38 )\n",
    "# points = [255, 256,\n",
    "#           234, 235, 236, 237, 238,\n",
    "#           214, 215, 216, 217, 218, 219,\n",
    "#           195, 196, 197, 198, 199, 200,\n",
    "#           175, 176, 177, 178, 179, 180, 181,\n",
    "#           156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
    "#           137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
    "#           116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
    "#           97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
    "#           77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91,\n",
    "#           59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
    "#           41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
    "#           27, 28, 29, 30, 31, 32]\n",
    "\n",
    "# ## Passirio station\n",
    "# lat = ( , )\n",
    "# lon = ( , )\n",
    "\n",
    "# # Plan basin\n",
    "out_basin = 'plan'\n",
    "# lat = (46.7145853, 46.8251415)\n",
    "# lon = (11.0198472, 11.117037)\n",
    "points = [137,\n",
    "          116, 117, 118, 119, 120,\n",
    "          97, 98, 99, 100, 101, 102,\n",
    "          77, 78, 79, 80, 81, 82,\n",
    "          59, 60, 61,\n",
    "          41]\n",
    "\n",
    "# # Plan station\n",
    "# lat = ( , )\n",
    "# lon = ( , )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin = 'plan'\n",
    "# variable = 'precipitation'\n",
    "# output_type = 'mean'\n",
    "# datetime_str = '20210816'\n",
    "\n",
    "# output_file = output_path + basin + '/' + variable + \\\n",
    "#                         '/' + output_type + '/' + datetime_str + '.csv'\n",
    "\n",
    "# extracted = pd.read_csv( output_file, parse_dates=['datetime'], sep=';' )\n",
    "# extracted.set_index('datetime', inplace=True)\n",
    "\n",
    "# extracted['2021-08-16 10:00:00':'2021-08-18 00:00:00'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_file = \"/media/windows/projects/hydrological_forecasting/machine_learning/data/observed/plan/precipitation/daily/obs/mean/\" + datetime_str + \".csv\"\n",
    "# print(obs_file)\n",
    "\n",
    "# obs = pd.read_csv( obs_file, parse_dates=['datetime'], sep=';' )\n",
    "# obs.set_index( 'datetime', inplace=True )\n",
    "\n",
    "# obs['2021-08-15 10:00:00':'2021-08-18 00:00:00'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = \"/media/windows/projects/hydrological_forecasting/machine_learning/data/observed/plan/precipitation/daily/filled/mean/\" + datetime_str + '.csv'\n",
    "\n",
    "# filled = pd.read_csv( output_file, parse_dates=['datetime'], sep=';' )\n",
    "# filled.set_index('datetime', inplace=True)\n",
    "\n",
    "# filled['2021-08-15 10:00:00':'2021-08-18 00:00:00'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime.strptime(start_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "end_date = dt.datetime.strptime(end_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "\n",
    "dates = [start_date + dt.timedelta(days=x)\n",
    "         for x in range(0, (end_date-start_date).days + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = glob.glob(data_path + '*/')\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles = range(1, ensemble_number + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir in dirs:\n",
    "\n",
    "#     # for basin in in_basins:\n",
    "\n",
    "#     for variable in variables:\n",
    "\n",
    "#         print('Variable: ' + variable)\n",
    "\n",
    "#         if variable == 'temperature':\n",
    "#             var = 't_2m'\n",
    "#         elif variable == 'precipitation':\n",
    "#             var = 'tot_prec'\n",
    "\n",
    "#         datetime_str = os.path.dirname(dir)[-8:]\n",
    "#         print(datetime_str)\n",
    "\n",
    "#         current_date = dt.datetime.strptime(datetime_str, '%Y%m%d')\n",
    "#         current_date = current_date.astimezone(timezone)\n",
    "\n",
    "#         if current_date in dates:\n",
    "\n",
    "#             print('Date: ' + str(current_date) )\n",
    "\n",
    "#             for output_type in output_types:\n",
    "\n",
    "#                 print('Type: ' + output_type)\n",
    "\n",
    "#                 current_dates = []\n",
    "#                 values = []\n",
    "#                 ensemble_index = [ str(e).zfill(3) for e in range(1,ensemble_number+1) ]\n",
    "#                 fct_df = pd.DataFrame( index=ensemble_index )\n",
    "#                 # fct_df_new = pd.DataFrame( index=ensemble_index )\n",
    "\n",
    "#                 for n in range(1, lead_hours+1):\n",
    "\n",
    "#                     current_dates.append(\n",
    "#                             current_date + dt.timedelta(hours=(int(init_ref) + n)))\n",
    "\n",
    "#                     n = str(n).zfill(3)\n",
    "\n",
    "#                     # print( 'Lead time: ' + n )\n",
    "\n",
    "#                     current_value = []\n",
    "#                     ensemble_value = []\n",
    "#                     for ensemble in ensembles:\n",
    "\n",
    "#                         ensemble_str = str(ensemble).zfill(3)\n",
    "#                         # print( \"Ens. \" + ensemble_str )\n",
    "                        \n",
    "#                         current_file = pd.read_csv(\n",
    "#                             dir + n + '/' + in_basin + '/' + var + '/' + ensemble_str + '/' + 'output.csv', index_col=0)\n",
    "\n",
    "#                         # current_file = current_file[current_file['lat'] <= lat[1]]\n",
    "#                         # current_file = current_file[current_file['lat'] >= lat[0]]\n",
    "#                         # current_file = current_file[current_file['lon'] <= lon[1]]\n",
    "#                         # current_file = current_file[current_file['lon'] >= lon[0]]\n",
    "\n",
    "#                         # evaluate the spatial mean of selected points\n",
    "#                         # current_value = current_file.mean()\n",
    "#                         if len(current_file) != 0:\n",
    "#                             current_value = current_file[current_file['ID'] == station_id]['values'].values[0]\n",
    "#                             # print( \"Ens. \" + ensemble_str + \" : \" + str(current_value) )\n",
    "#                         else:\n",
    "#                             print( \"Ens. \" + ensemble_str + \" MISSING \" )\n",
    "#                             break\n",
    "\n",
    "#                         if variable == 'temperature':\n",
    "#                             ensemble_value.append(\n",
    "#                                 current_value - 273.15)\n",
    "#                         elif variable == 'precipitation':\n",
    "#                             ensemble_value.append(\n",
    "#                                 abs(current_value))\n",
    "#                         else:\n",
    "#                             print(\"ERROR: not a valid variable!\")\n",
    "                    \n",
    "#                     fct_df[ n ] = ensemble_value\n",
    "#                     # if variable == 'precipitation':\n",
    "#                     #     # print( ensemble_value )\n",
    "#                     #     ensemble_value = [round(ensemble_value[0], 2)] + [round(\n",
    "#                     #         ensemble_value[i] - ensemble_value[i-1], 2) for i in range(1, len(ensemble_value))]\n",
    "\n",
    "#                 if variable == 'precipitation':\n",
    "#                     ### to solve cumulative problem\n",
    "#                     for n in range(1, lead_hours+1):\n",
    "                        \n",
    "#                         lead_hour_str = str(n).zfill(3)\n",
    "#                         if n-1 > 0:\n",
    "#                             lead_hour_str_last = str(n-1).zfill(3)\n",
    "\n",
    "#                             fct_df.sort_values(by=lead_hour_str_last, inplace=True)\n",
    "#                             to_sort = fct_df[lead_hour_str]\n",
    "#                             fct_df.drop(columns=lead_hour_str, inplace=True)\n",
    "#                             fct_df[lead_hour_str] = to_sort.sort_values().values\n",
    "                \n",
    "#                     fct_df = fct_df.T\n",
    "            \n",
    "#                     for ens in ensembles:\n",
    "\n",
    "#                         ens = str(ens).zfill(3)\n",
    "\n",
    "#                         ens_value = fct_df[ens].values\n",
    "\n",
    "#                         # print(ens_value)\n",
    "\n",
    "#                         val = []\n",
    "#                         val.append( ens_value[0] )\n",
    "#                         for i in range(1, len(ens_value)):\n",
    "#                             val.append( ens_value[i] - ens_value[i-1] )\n",
    "\n",
    "#                         # print(tmp)\n",
    "\n",
    "#                         fct_df[ens] = val\n",
    "                \n",
    "#                 else:\n",
    "#                     fct_df = fct_df.T\n",
    "\n",
    "#                 # define the type of output\n",
    "#                 if output_type == 'mean':\n",
    "#                     values = fct_df.mean(axis=1).values\n",
    "#                 elif output_type == 'median':\n",
    "#                     values = fct_df.median(axis=1).values\n",
    "#                 elif output_type == 'first_quantile':\n",
    "#                     values = fct_df.quantile(0.15,axis=1).values\n",
    "#                 elif output_type == 'third_quantile':\n",
    "#                     values = fct_df.quantile(0.85,axis=1).values\n",
    "#                 else:\n",
    "#                     print(\"ERROR: not a valid output_type!\")\n",
    "\n",
    "#                 data = pd.DataFrame(values, index=current_dates, columns=['values'])\n",
    "#                 data.index.name = 'datetime'\n",
    "#                 data.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in data.index ]\n",
    "\n",
    "#                 # if variable == 'precipitation':\n",
    "#                 #     data['values'] = [round(data.iloc[0]['values'], 2)] + [round(\n",
    "#                 #         data.iloc[i]['values'] - data.iloc[i-1]['values'], 2) for i in range(1, len(data))]\n",
    "            \n",
    "#                 output_file = output_path + out_basin + '/' + variable + '/deterministic/' + output_type + '/' + datetime_str + '.csv'\n",
    "#                 mkNestedDir(os.path.dirname(output_file))\n",
    "#                 data.to_csv(output_file, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir in dirs:\n",
    "\n",
    "#     print(dir)\n",
    "\n",
    "#     # for basin in in_basins:\n",
    "\n",
    "#     for variable in variables:\n",
    "\n",
    "#         if variable == 'temperature':\n",
    "#             var = 't_2m'\n",
    "#         elif variable == 'precipitation':\n",
    "#             var = 'tot_prec'\n",
    "\n",
    "#         datetime_str = os.path.dirname(dir)[-8:]\n",
    "#         print(datetime_str)\n",
    "\n",
    "#         current_date = dt.datetime.strptime(datetime_str, '%Y%m%d')\n",
    "\n",
    "#         if current_date in dates:\n",
    "\n",
    "#             print('Variable: ' + variable)\n",
    "\n",
    "#             # print( n )\n",
    "#             plots = []\n",
    "#             for output_type in output_types:\n",
    "\n",
    "#                 print(output_type)\n",
    "\n",
    "#                 # current_data = None\n",
    "\n",
    "#                 output_file = output_path + out_basin + '/' + variable + \\\n",
    "#                     '/' + output_type + '/' + datetime_str + '.csv'\n",
    "#                 current_data = pd.read_csv(\n",
    "#                     output_file, parse_dates=True, index_col=0, sep=';')\n",
    "\n",
    "#                 plt_conf = {}\n",
    "\n",
    "#                 if output_type == 'mean':\n",
    "#                     # plt_conf[\"color\"] = '#5e3c99'\n",
    "#                     continue\n",
    "#                 elif output_type == 'median':\n",
    "#                     plt_conf[\"color\"] = '#e66101'\n",
    "#                 elif output_type == 'first_quantile':\n",
    "#                     plt_conf[\"color\"] = '#fdb863'\n",
    "#                 elif output_type == 'third_quantile':\n",
    "#                     plt_conf[\"color\"] = '#8078bc'\n",
    "#                 else:\n",
    "#                     print(\"ERROR: not a valid output_type!\")\n",
    "\n",
    "#                 plt_conf[\"label\"] = output_type\n",
    "#                 plots.append((current_data, plt_conf))\n",
    "\n",
    "#             output_image = output_path + \"img/deterministic/\" + out_basin + \"/\" + variable + \\\n",
    "#                 '/' + datetime_str + \".\" + output_format\n",
    "#             createPlot(plots,  \"X $[m^3/day]$\", \"Y\", output_image,\n",
    "#                         output_format=output_format, my_dpi=50)\n",
    "\n",
    "#             output_image_hd = output_path + \"img_HD/deterministic/\" + out_basin + \"/\" + \\\n",
    "#                 variable + '/' + datetime_str + \".\" + output_format\n",
    "#             createPlot(plots,  \"X $[m^3/day]$\", \"Y\", output_image_hd,\n",
    "#                         output_format=output_format, my_dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract data for each point in the out_basin\n",
    "\n",
    "for dir in dirs:\n",
    "\n",
    "    # for basin in in_basins:\n",
    "\n",
    "    for variable in variables:\n",
    "\n",
    "        print('Variable: ' + variable)\n",
    "\n",
    "        if variable == 'temperature':\n",
    "            var = 't_2m'\n",
    "        elif variable == 'precipitation':\n",
    "            var = 'tot_prec'\n",
    "\n",
    "        datetime_str = os.path.dirname(dir)[-8:]\n",
    "        print(datetime_str)\n",
    "\n",
    "        current_date = dt.datetime.strptime(datetime_str, '%Y%m%d')\n",
    "        current_date = current_date.astimezone(timezone)\n",
    "\n",
    "        if current_date in dates:\n",
    "\n",
    "            print('Date: ' + str(current_date) )\n",
    "\n",
    "            for point in points:\n",
    "\n",
    "                # print('Type: ' + output_type)\n",
    "\n",
    "                current_dates = []\n",
    "                values = []\n",
    "                ensemble_index = [ str(e).zfill(3) for e in range(1,ensemble_number+1) ]\n",
    "                fct_df = pd.DataFrame( index=ensemble_index )\n",
    "                # fct_df_new = pd.DataFrame( index=ensemble_index )\n",
    "\n",
    "                for n in range(1, lead_hours+1):\n",
    "\n",
    "                    current_dates.append(\n",
    "                            current_date + dt.timedelta(hours=(int(init_ref) + n)))\n",
    "\n",
    "                    n = str(n).zfill(3)\n",
    "\n",
    "                    # print( 'Lead time: ' + n )\n",
    "\n",
    "                    current_value = []\n",
    "                    ensemble_value = []\n",
    "                    for ensemble in ensembles:\n",
    "\n",
    "                        ensemble_str = str(ensemble).zfill(3)\n",
    "                        # print( \"Ens. \" + ensemble_str )\n",
    "                        \n",
    "                        current_file = pd.read_csv(\n",
    "                            dir + n + '/' + in_basin + '/' + var + '/' + ensemble_str + '/' + 'output.csv', index_col=0)\n",
    "\n",
    "                        # current_file = current_file[current_file['lat'] <= lat[1]]\n",
    "                        # current_file = current_file[current_file['lat'] >= lat[0]]\n",
    "                        # current_file = current_file[current_file['lon'] <= lon[1]]\n",
    "                        # current_file = current_file[current_file['lon'] >= lon[0]]\n",
    "\n",
    "                        # evaluate the spatial mean of selected points\n",
    "                        # current_value = current_file.mean()\n",
    "\n",
    "                        current_value = current_file[current_file['ID'] == int(point)]['values'].values[0]\n",
    "                        # print( \"Ens. \" + ensemble_str + \" : \" + str(current_value) )\n",
    "\n",
    "                        if variable == 'temperature':\n",
    "                            ensemble_value.append( round(\n",
    "                                current_value - 273.15, 2) )\n",
    "                        elif variable == 'precipitation':\n",
    "                            ensemble_value.append( round(\n",
    "                                abs(current_value), 2) )\n",
    "                        else:\n",
    "                            print(\"ERROR: not a valid variable!\")\n",
    "                    \n",
    "                    fct_df[ n ] = ensemble_value\n",
    "\n",
    "                if variable == 'precipitation':\n",
    "\n",
    "                    ## to solve cumulative problem\n",
    "                    # for n in range(1, lead_hours+1):\n",
    "                        \n",
    "                    #     lead_hour_str = str(n).zfill(3)\n",
    "                    #     if n-1 > 0:\n",
    "                    #         lead_hour_str_last = str(n-1).zfill(3)\n",
    "\n",
    "                    #         fct_df.sort_values(by=lead_hour_str_last, inplace=True)\n",
    "                    #         to_sort = fct_df[lead_hour_str]\n",
    "                    #         fct_df.drop(columns=lead_hour_str, inplace=True)\n",
    "                    #         fct_df[lead_hour_str] = to_sort.sort_values().values\n",
    "\n",
    "                    ## to reorder the last based on the next to last\n",
    "                    bug_hour = 16\n",
    "                    lead_time_bug = str(bug_hour).zfill(3)\n",
    "                    before_bug = str(bug_hour-1).zfill(3)\n",
    "                    after_bug = str(bug_hour+1).zfill(3)\n",
    "                    fct_df.drop(columns=lead_time_bug, inplace=True)\n",
    "                    fct_df[lead_time_bug] = (fct_df[after_bug].values + fct_df[before_bug].values)/2\n",
    "\n",
    "                    # bug_hour = 44\n",
    "                    # next_to_bug = str(bug_hour-1).zfill(3)\n",
    "                    # bug_lead_time = str(bug_hour).zfill(3)\n",
    "                    # fct_df.sort_values(by=next_to_bug, inplace=True)\n",
    "                    # to_sort = fct_df[bug_lead_time]\n",
    "                    # fct_df.drop(columns=bug_lead_time, inplace=True)\n",
    "                    # fct_df[bug_lead_time] = to_sort.sort_values().values\n",
    "\n",
    "                    ## to reorder the last based on the next to last\n",
    "                    next_to_last = str(lead_hours-1).zfill(3)\n",
    "                    last_lead_time = str(lead_hours).zfill(3)\n",
    "                    fct_df.sort_values(by=next_to_last, inplace=True)\n",
    "                    to_sort = fct_df[last_lead_time]\n",
    "                    fct_df.drop(columns=last_lead_time, inplace=True)\n",
    "                    fct_df[last_lead_time] = to_sort.sort_values().values\n",
    "\n",
    "                    fct_final = pd.DataFrame( index=ensemble_index )\n",
    "                    for en in range(1,lead_hours+1):\n",
    "                        fct_final[str(en).zfill(3)] = fct_df[str(en).zfill(3)]\n",
    "\n",
    "                    fct_df = fct_final.T\n",
    "            \n",
    "                    for ens in ensembles:\n",
    "\n",
    "                        ens = str(ens).zfill(3)\n",
    "\n",
    "                        ens_value = fct_df[ens].values\n",
    "\n",
    "                        # print(ens_value)\n",
    "\n",
    "                        val = []\n",
    "                        val.append( ens_value[0] )\n",
    "                        for i in range(1, len(ens_value)):\n",
    "                            val.append( ens_value[i] - ens_value[i-1] )\n",
    "\n",
    "                        fct_df[ens] = [round(v, 2) for v in val]\n",
    "                else:\n",
    "                    fct_df = fct_df.T\n",
    "              \n",
    "                for output_type in output_types: # define the type of output\n",
    "                    if output_type == 'mean':\n",
    "                        fct_df_tmp = pd.DataFrame(fct_df.mean(axis=1).values, index=current_dates, columns=['values'])\n",
    "                    elif output_type == 'median':\n",
    "                        fct_df_tmp = pd.DataFrame(fct_df.median(axis=1).values, index=current_dates, columns=['values'])\n",
    "                    elif output_type == 'first_quantile':\n",
    "                        fct_df_tmp = pd.DataFrame(fct_df.quantile(0.15,axis=1).values, index=current_dates, columns=['values'])\n",
    "                    elif output_type == 'third_quantile':\n",
    "                        fct_df_tmp = pd.DataFrame(fct_df.quantile(0.85,axis=1).values, index=current_dates, columns=['values'])\n",
    "                    else:\n",
    "                        print(\"ERROR: not a valid output_type!\")  \n",
    "\n",
    "                    fct_df_tmp.index = current_dates\n",
    "                    fct_df_tmp.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in fct_df_tmp.index ]\n",
    "                    fct_df_tmp.index.name = \"datetime\"\n",
    "                \n",
    "                    output_file = output_path + out_basin + '/' + variable + '/deterministic/' + output_type + '/' + str(point).zfill(3) + '/' + datetime_str + '.csv'\n",
    "                    mkNestedDir(os.path.dirname(output_file))\n",
    "                    fct_df_tmp.to_csv(output_file, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in dirs:\n",
    "\n",
    "    datetime_str = os.path.dirname(dir)[-8:]\n",
    "    print(datetime_str)\n",
    "\n",
    "    for variable in variables:\n",
    "\n",
    "        print('Variable: ' + variable)\n",
    "\n",
    "        point_matrix = pd.DataFrame()\n",
    "\n",
    "        for output_type in output_types: # define the type of output\n",
    "            for point in points:\n",
    "\n",
    "                point_id = str(point).zfill(3)\n",
    "\n",
    "                file_to_read = output_path + out_basin + '/' + variable + '/deterministic/' + output_type + '/' + point_id + '/' + datetime_str + '.csv'\n",
    "                # print(file_to_read)\n",
    "                current_file = pd.read_csv( file_to_read, parse_dates=[0], index_col=0, sep=';' )\n",
    "\n",
    "                if len(point_matrix.index) == 0:\n",
    "                    point_matrix.index = current_file.index\n",
    "                point_matrix[point_id] = [ round(v[0],2) for v in current_file.values ]\n",
    "\n",
    "            mean_matrix = pd.DataFrame(point_matrix.mean(axis=1).round(2), columns=['values'])\n",
    "\n",
    "            mean_matrix.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in mean_matrix.index ]\n",
    "            mean_matrix.index.name = 'datetime'\n",
    "            mean_matrix.columns = [str(m).zfill(3) for m in mean_matrix.columns]\n",
    "\n",
    "            output_file = output_path + out_basin + '/' + variable + '/deterministic/' + output_type + '/' + 'spatial_mean/' + datetime_str + '.csv'\n",
    "            mkNestedDir(os.path.dirname(output_file))\n",
    "            mean_matrix.to_csv(output_file, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in dirs:\n",
    "\n",
    "    datetime_str = os.path.dirname(dir)[-8:]\n",
    "    print(datetime_str)\n",
    "\n",
    "    for variable in variables:\n",
    "\n",
    "        print('Variable: ' + variable)\n",
    "\n",
    "        point_matrix = pd.DataFrame()\n",
    "\n",
    "        for point in points:\n",
    "\n",
    "            point_id = str(point).zfill(3)\n",
    "\n",
    "            file_to_read = output_path + out_basin + '/' + variable + '/ensemble/' + point_id + '/' + datetime_str + '.csv'\n",
    "\n",
    "            current_file = pd.read_csv( file_to_read, parse_dates=[0], index_col=0, sep=';' )\n",
    "                \n",
    "            tmp = []\n",
    "            for hour in range( lead_hours ):\n",
    "                tmp.append( current_file.iloc[hour].to_list() )\n",
    "            \n",
    "            point_matrix[point_id] = tmp\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir in dirs:\n",
    "\n",
    "#     datetime_str = os.path.dirname(dir)[-8:]\n",
    "#     print(datetime_str)\n",
    "\n",
    "#     for variable in variables:\n",
    "\n",
    "#         print('Variable: ' + variable)\n",
    "\n",
    "#         point_matrix = pd.DataFrame()\n",
    "\n",
    "#         for point in points:\n",
    "\n",
    "#             point_id = str(point).zfill(3)\n",
    "#             # print(point_id)\n",
    "\n",
    "#         # datetime_str = os.path.dirname(dir)[-8:]\n",
    "#         # print(datetime_str)\n",
    "\n",
    "#         # current_date = dt.datetime.strptime(datetime_str, '%Y%m%d')\n",
    "\n",
    "#         # if current_date in dates:\n",
    "\n",
    "#             # print('Date: ' + str(current_date) )\n",
    "\n",
    "#             file_to_read = output_path + out_basin + '/' + variable + '/ensemble/' + point_id + '/' + datetime_str + '.csv'\n",
    "#             # files_to_read = glob.glob(file_to_read)\n",
    "\n",
    "#             current_file = pd.read_csv( file_to_read, parse_dates=[0], index_col=0, sep=';' )\n",
    "#             # print(files_to_read)\n",
    "#             # for f in files_to_read:\n",
    "\n",
    "#                 # datetime_str = os.path.dirname(f)[-8:]\n",
    "#                 # print(datetime_str)\n",
    "\n",
    "#                 # current_file = pd.read_csv( f, parse_dates=True, index_col=0, sep=';' )\n",
    "                \n",
    "#             tmp = []\n",
    "#             for hour in range( lead_hours ):\n",
    "#                 tmp.append( current_file.iloc[hour].to_list() )\n",
    "            \n",
    "#             point_matrix[point_id] = tmp\n",
    "\n",
    "#         point_matrix.index = current_file.index\n",
    "\n",
    "#         mean_matrix = pd.DataFrame(index=[l for l in range(1,ensemble_number+1)])\n",
    "\n",
    "#         for i in range(lead_hours):\n",
    "#             ensemble_spatial_mean = []\n",
    "#             for k in range(ensemble_number):\n",
    "#                 ensemble_array = []\n",
    "#                 for j in points:\n",
    "#                     point_id = str(j).zfill(3)\n",
    "#                     ensemble_array.append( point_matrix.iloc[i][point_id][k] )\n",
    "#                 ensemble_spatial_mean.append( round(np.mean(ensemble_array), 2) )\n",
    "#             mean_matrix[point_matrix.index[i]] = ensemble_spatial_mean\n",
    "\n",
    "#         mean_matrix = mean_matrix.T\n",
    "#         mean_matrix.index.name = 'datetime'\n",
    "#         mean_matrix.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in mean_matrix.index ]\n",
    "\n",
    "#         output_file = output_path + out_basin + '/' + variable + '/ensemble/spatial_mean/' + datetime_str + '.csv'\n",
    "#         mkNestedDir(os.path.dirname(output_file))\n",
    "#         mean_matrix.to_csv(output_file, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### for saving into the DB\n",
    "\n",
    "# for variable in variables:\n",
    "\n",
    "#     print('Variable: ' + variable)\n",
    "\n",
    "#     point_matrix = pd.DataFrame()\n",
    "\n",
    "#     for point in points:\n",
    "\n",
    "#         point_id = str(point).zfill(3)\n",
    "\n",
    "#     # datetime_str = os.path.dirname(dir)[-8:]\n",
    "#     # print(datetime_str)\n",
    "\n",
    "#     # current_date = dt.datetime.strptime(datetime_str, '%Y%m%d')\n",
    "\n",
    "#     # if current_date in dates:\n",
    "\n",
    "#         # print('Date: ' + str(current_date) )\n",
    "\n",
    "#         file_to_read = output_path + out_basin + '/' + variable + '/' + point_id + '/' + '*.csv'\n",
    "#         files_to_read = glob.glob(file_to_read)\n",
    "\n",
    "#         # print(files_to_read)\n",
    "#         for f in files_to_read:\n",
    "\n",
    "#             datetime_str = os.path.dirname(dir)[-8:]\n",
    "#             # print(datetime_str)\n",
    "\n",
    "#             current_file = pd.read_csv( f, parse_dates=True, index_col=0, sep=';' )\n",
    "            \n",
    "#             tmp = []\n",
    "#             for hour in range( lead_hours ):\n",
    "#                 tmp.append( current_file.iloc[hour].to_list() )\n",
    "            \n",
    "#             point_matrix[point_id] = tmp\n",
    "\n",
    "#     point_matrix.index = current_file.index\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
