{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ DATA AND CONVERT INTO CSV\n",
    "1. setup the wdir to the directory where the grib2 data is collected\n",
    "2. each directory of the wdir will be opened and the grib inside it processed\n",
    "    a. each grib file will be converted in a grid, based on DWD weights\n",
    "    b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = \"/home/daniele/documents/github/ftt01/phd/projects/hydrological_forecasting/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTs\n",
    "import sys, os\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# to link the lib in py scripts as well\n",
    "os.chdir( wdir )\n",
    "sys.path.insert( 0, os.path.join(os.path.abspath(os.getcwd()),'lib') )\n",
    "\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "data_path = \"/media/windows/projects/hydrological_forecasting/machine_learning/data/forecast/icon-eu/\"\n",
    "\n",
    "# variable = 'TOT_PREC'\n",
    "variable = 'T_2M'\n",
    "lead_hours = 8\n",
    "ensemble_number = 1\n",
    "\n",
    "### READ THIS FROM FILE!!!!!\n",
    "init_date = dt.datetime.strptime('20210614T06:00:00', '%Y%m%dT%H:%M:%S')\n",
    "\n",
    "lat = ( 46.2, 47.2 )\n",
    "lon = ( 10.2, 12.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_to_save = data_path + 'tmp/'\n",
    "\n",
    "print(dir_to_save)\n",
    "\n",
    "mkNestedDir(dir_to_save)\n",
    "os.chdir(dir_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# download the data\n",
    "subprocess.run('''docker run --rm --volume $(pwd):/local \\\n",
    "    deutscherwetterdienst/downloader downloader \\\n",
    "    --model icon-eu \\\n",
    "    --single-level-fields t_2m,tot_prec \\\n",
    "    --max-time-step {lead_hours} \\\n",
    "    --directory /local'''.format(lead_hours=lead_hours),\n",
    "                shell=True, check=True,\n",
    "                executable='/bin/bash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = glob.glob( data_path + '*/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in dirs:\n",
    "\n",
    "    os.chdir(el)\n",
    "\n",
    "    lead_time_array = []\n",
    "    for n in range(1, lead_hours+1):\n",
    "        n = str(n).zfill(3)\n",
    "        lead_time_array.append(n)\n",
    "\n",
    "    full_data = pd.DataFrame(columns=['ID', 'lat', 'lon'] + lead_time_array)\n",
    "\n",
    "    for n in range(1, lead_hours+1):\n",
    "\n",
    "        n = str(n).zfill(3)\n",
    "        print(n)\n",
    "\n",
    "        # create and move into the current_file_path\n",
    "        current_file_path = el + n + '/'\n",
    "        mkNestedDir(current_file_path)\n",
    "        os.chdir(current_file_path)\n",
    "\n",
    "        # identify and move current_file into current_file_path\n",
    "        print( el + '*' + variable + '*.grib2' )\n",
    "        current_file = glob.glob(el + '*' + variable + '*.grib2')[0]\n",
    "        mv_process = \"mv {} {}\".format(\n",
    "            current_file, current_file_path + os.path.basename(current_file))\n",
    "        subprocess.run(mv_process, shell=True,\n",
    "                       check=True, executable='/bin/bash')\n",
    "\n",
    "        # extract data to output.csv\n",
    "        extraction_process = '''docker run --rm --volume $(pwd):/local \\\n",
    "            deutscherwetterdienst/python-eccodes grib_get_data -p date,time,stepRange,shortName {} > output.csv'''\n",
    "        extraction_process = extraction_process.format(\n",
    "            os.path.basename(current_file))\n",
    "        subprocess.run(extraction_process, shell=True,\n",
    "                       check=True, executable='/bin/bash')\n",
    "\n",
    "        # read exported data and cut to the ROI\n",
    "        data_df = pd.read_csv('output.csv', sep='\\s+', skiprows=0, header=None,\n",
    "                              names=['lat', 'lon', 'values', 'date', 'time', 'step_range', 'name'], low_memory=False)\n",
    "        data_df = data_df[data_df[\"lat\"] != 'Latitude,']\n",
    "        data_df = data_df.astype({'lat': float, 'lon': float, 'values': float,\n",
    "                                 'date': str, 'time': str, 'step_range': str, 'name': str})\n",
    "\n",
    "        data_df = data_df[data_df['lat'] >= lat[0]]\n",
    "        data_df = data_df[data_df['lat'] <= lat[1]]\n",
    "        data_df = data_df[data_df['lon'] >= lon[0]]\n",
    "        data_df = data_df[data_df['lon'] <= lon[1]]\n",
    "\n",
    "        # export data to a new structure\n",
    "        interruptor = int(len(data_df) / ensemble_number)\n",
    "        # print(interruptor)\n",
    "\n",
    "        full_data['ID'] = range(1, interruptor+1)\n",
    "        full_data.set_index('ID', inplace=True)\n",
    "\n",
    "        metadata = True\n",
    "        for ens in range(ensemble_number):\n",
    "\n",
    "            m = str(ens+1).zfill(3)\n",
    "            ens_file_path = current_file_path + m + '/'\n",
    "            mkNestedDir(ens_file_path)\n",
    "\n",
    "            current_data = pd.DataFrame(columns=['lat','lon','values'])\n",
    "            lats = []\n",
    "            lons = []\n",
    "            vals = []\n",
    "            for i in range(interruptor*ens, interruptor*(1+ens)):\n",
    "\n",
    "                point_id = i + 1 - interruptor*ens\n",
    "\n",
    "                lats.append( data_df.iloc[i]['lat'] )\n",
    "                lons.append( data_df.iloc[i]['lon'] )\n",
    "                vals.append( data_df.iloc[i]['values'] )\n",
    "                \n",
    "                \n",
    "                ## full_data creation\n",
    "                if metadata == True:\n",
    "                    full_data.loc[point_id]['lat'] = data_df.iloc[i]['lat']\n",
    "                    full_data.loc[point_id]['lon'] = data_df.iloc[i]['lon']\n",
    "\n",
    "                if ens == 0:\n",
    "                    full_data.loc[point_id][n] = [data_df.iloc[i]['values']]\n",
    "                else:\n",
    "                    full_data.loc[point_id][n] = full_data.loc[point_id][n] + \\\n",
    "                        [data_df.iloc[i]['values']]\n",
    "\n",
    "                # print(data_df.iloc[i]['values'])\n",
    "\n",
    "            current_data['lat'] = lats\n",
    "            current_data['lon'] = lons\n",
    "            current_data['values'] = vals\n",
    "\n",
    "            current_data.to_csv( ens_file_path + 'output.csv' )\n",
    "\n",
    "            print( ens_file_path )\n",
    "\n",
    "            metadata = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.loc[128]['008'][0] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = full_data[ full_data['lat'] >= 46.75 ]\n",
    "tmp = tmp[ full_data['lat'] <= 46.85 ]\n",
    "tmp = tmp[ full_data['lon'] >= 11.1 ]\n",
    "tmp = tmp[ full_data['lon'] <= 11.35 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "dates = []\n",
    "\n",
    "for n in range(1, lead_hours+1):\n",
    "\n",
    "    dates.append( init_date + dt.timedelta(hours=n) )\n",
    "    \n",
    "    series.append( tmp.iloc[0][0] - 273.15 )\n",
    "\n",
    "    # n = str(n).zfill(3)\n",
    "    # if variable == 't_2m':\n",
    "    #     series.append( tmp.iloc[0][0] - 273.15 )\n",
    "    # else:\n",
    "    #     series.append( tmp.iloc[0][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame( series, index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run --rm --volume $(pwd):/local \\\n",
    "#     deutscherwetterdienst/downloader downloader \\\n",
    "#     --model icon \\\n",
    "#     --single-level-fields t_2m,tot_prec \\\n",
    "#     --max-time-step 5 \\\n",
    "#     --directory /local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --rm \\\n",
    "#     --volume $(pwd):/local \\\n",
    "#     --env INPUT_FILE=/local \\\n",
    "#     --env OUTPUT_FILE=/local \\\n",
    "#     deutscherwetterdienst/regrid:icon-eu-eps \\\n",
    "#     /convert.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/media/windows/projects/hydrological_forecasting/machine_learning/data/forecast/icon-eu/tmp/001/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --rm --mount type=bind,source=\"$(pwd)\"/,target=/local deutscherwetterdienst/python-eccodes grib_ls icon-eu_europe_regular-lat-lon_single-level_2021102703_000_TOT_PREC.grib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
