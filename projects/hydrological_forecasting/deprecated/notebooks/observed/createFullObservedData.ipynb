{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = \"/home/daniele/documents/github/ftt01/phd/projects/hydrological_forecasting/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTs\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# to link the lib in py scripts as well\n",
    "os.chdir(wdir)\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(os.getcwd()), 'lib'))\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data(current_data, additional_data):\n",
    "\n",
    "    current_data = current_data.reset_index()\n",
    "    additional_data = additional_data.reset_index()\n",
    "\n",
    "    current_data = pd.concat([current_data[current_data['datetime'].isin(\n",
    "        additional_data['datetime']) == False], additional_data], ignore_index=True)\n",
    "\n",
    "    # print(data)\n",
    "    current_data.dropna(subset=['datetime'], inplace=True)\n",
    "    current_data.sort_values(by=['datetime'], inplace=True)\n",
    "\n",
    "    current_data = current_data.set_index('datetime')\n",
    "    current_data = current_data[current_data.index.notnull()]\n",
    "\n",
    "    return current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_str = '20080615T00:00:00'\n",
    "end_date_str = '20211016T00:00:00'\n",
    "timezone_str = 'Europe/Rome'\n",
    "timezone = ZoneInfo(timezone_str)\n",
    "\n",
    "start_date = dt.datetime.strptime(start_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "end_date = dt.datetime.strptime(end_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "\n",
    "dates = [start_date + dt.timedelta(days=x)\n",
    "         for x in range(0, (end_date-start_date).days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp_old = pd.read_csv(\"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/streamflow/original_data/155.txt\", parse_dates=[0], skiprows=4, header=None, index_col=0, names=['datetime', 'values'])\n",
    "data_tmp_old = data_tmp_old.replace(-999.0,np.nan)\n",
    "try:\n",
    "    data_tmp_old = data_tmp_old.tz_localize(timezone_str,ambiguous='infer',nonexistent='NaT')\n",
    "except:\n",
    "    data_tmp_old = data_tmp_old.tz_localize(timezone_str,ambiguous=True,nonexistent='NaT')\n",
    "# data_tmp_old = data_tmp_old.tz_localize(None)\n",
    "data_tmp_old = data_tmp_old[[not(a) for a in pd.isna(data_tmp_old.index)]]\n",
    "\n",
    "data_tmp = pd.read_csv(\"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/streamflow/original_data/20750PG.csv\", parse_dates=[0], index_col=0)\n",
    "data_tmp = data_tmp.tz_convert(timezone_str)\n",
    "# data_tmp = data_tmp.tz_localize(None)\n",
    "\n",
    "output_file = \"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/streamflow/\" + \"20750PG.csv\"\n",
    "current_data = append_data(data_tmp_old, data_tmp)\n",
    "\n",
    "current_data = current_data.resample('H').mean()\n",
    "current_data.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in current_data.index ]\n",
    "current_data.index.name = 'datetime'\n",
    "\n",
    "current_data.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp_old = pd.read_csv(\"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/precipitation/original_data/128.txt\", parse_dates=[0], skiprows=4, header=None, index_col=0, names=['datetime', 'values'])\n",
    "data_tmp_old = data_tmp_old.replace(-999.0,np.nan)\n",
    "try:\n",
    "    data_tmp_old = data_tmp_old.tz_localize(timezone_str,ambiguous='infer',nonexistent='NaT')\n",
    "except:\n",
    "    data_tmp_old = data_tmp_old.tz_localize(timezone_str,ambiguous=True,nonexistent='NaT')\n",
    "# data_tmp_old = data_tmp_old.tz_localize(None)\n",
    "data_tmp_old = data_tmp_old[[not(a) for a in pd.isna(data_tmp_old.index)]]\n",
    "\n",
    "data_tmp = pd.read_csv(\"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/precipitation/original_data/20500MS.csv\", parse_dates=[0], index_col=0)\n",
    "data_tmp = data_tmp.tz_convert(timezone_str)\n",
    "# data_tmp = data_tmp.tz_localize(None)\n",
    "\n",
    "output_file = \"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/precipitation/\" + \"20500MS.csv\"\n",
    "current_data = append_data(data_tmp_old, data_tmp)\n",
    "\n",
    "current_data = current_data.resample('H').sum()\n",
    "current_data.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in current_data.index ]\n",
    "current_data.index.name = 'datetime'\n",
    "\n",
    "current_data.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ FILE FROM NICOLA\n",
    "data_tmp_old = pd.read_csv(\"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/temperature/original_data/128.txt\", parse_dates=[0], skiprows=4, header=None, index_col=0, names=['datetime', 'values'])\n",
    "data_tmp_old = data_tmp_old.replace(-999.0,np.nan)\n",
    "try:\n",
    "    data_tmp_old = data_tmp_old.tz_localize(timezone_str,ambiguous='infer',nonexistent='NaT')\n",
    "except:\n",
    "    data_tmp_old = data_tmp_old.tz_localize(timezone_str,ambiguous=True,nonexistent='NaT')\n",
    "# data_tmp_old = data_tmp_old.tz_localize(None)\n",
    "data_tmp_old = data_tmp_old[[not(a) for a in pd.isna(data_tmp_old.index)]]\n",
    "\n",
    "### READ FILE FROM AUTOMATIC DOWNLOAD\n",
    "data_tmp = pd.read_csv(\"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/temperature/original_data/20500MS.csv\", parse_dates=[0], index_col=0)\n",
    "data_tmp = data_tmp.tz_convert(timezone_str)\n",
    "# data_tmp = data_tmp.tz_localize(None)\n",
    "\n",
    "output_file = \"/media/windows/projects/hydro_forecasting/machine_learning/data/observed/plan/temperature/\" + \"20500MS.csv\"\n",
    "current_data = append_data(data_tmp_old, data_tmp)\n",
    "\n",
    "current_data = current_data.resample('H').mean()\n",
    "current_data.index = [ dt.datetime.strftime(i, format='%Y-%m-%d %H:%M:%S') for i in current_data.index ]\n",
    "current_data.index.name = 'datetime'\n",
    "\n",
    "current_data.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date_str = '20090329T00:00:00'\n",
    "# end_date_str = '20090329T23:00:00'\n",
    "# timezone_str = 'Europe/Rome'\n",
    "# timezone = ZoneInfo(timezone_str)\n",
    "\n",
    "# start_date = dt.datetime.strptime(start_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "# end_date = dt.datetime.strptime(end_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "\n",
    "# dates = [start_date + dt.timedelta(hours=x)\n",
    "#          for x in range(0, ((end_date-start_date).days*24)+(end_date.hour-start_date.hour)+1)]\n",
    "\n",
    "# data_tmp_old[start_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date_str = '20091025T00:00:00'\n",
    "# end_date_str = '20091025T23:00:00'\n",
    "# timezone_str = 'Europe/Rome'\n",
    "# timezone = ZoneInfo(timezone_str)\n",
    "\n",
    "# start_date = dt.datetime.strptime(start_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "# end_date = dt.datetime.strptime(end_date_str, '%Y%m%dT%H:%M:%S').replace(tzinfo=ZoneInfo(timezone_str))\n",
    "\n",
    "# dates = [start_date + dt.timedelta(hours=x)\n",
    "#          for x in range(0, ((end_date-start_date).days*24)+(end_date.hour-start_date.hour)+1)]\n",
    "\n",
    "# data_tmp_old[start_date:end_date]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
